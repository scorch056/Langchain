{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000013ADE7B98D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000013ADE7BE110>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\", api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Swastik, it's nice to meet you!\\n\\nThat's an exciting field to be in. What kind of AI engineering do you specialize in? Are you working on anything interesting at the moment?  \\n\\nI'm always eager to learn more about what people are doing in the world of AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 23, 'total_tokens': 91, 'completion_time': 0.123636364, 'prompt_time': 0.002326875, 'queue_time': 0.236906344, 'total_time': 0.125963239}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-047c9364-4b29-431f-9379-90c15df2d515-0', usage_metadata={'input_tokens': 23, 'output_tokens': 68, 'total_tokens': 91})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is swastik and I am a AI engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Swastik and that you are an AI engineer!  \\n\\nIs there anything else you'd like to tell me about yourself or your work? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 113, 'total_tokens': 153, 'completion_time': 0.072727273, 'prompt_time': 0.010397149, 'queue_time': 0.250552772, 'total_time': 0.083124422}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8b5e711e-71c2-4312-9ddd-d9241ee38168-0', usage_metadata={'input_tokens': 113, 'output_tokens': 40, 'total_tokens': 153})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make an artificial message history and see that the model remembers the past conversation and responds accordingly\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is swastik and I am a AI engineer\"),\n",
    "        AIMessage(content=\"Hello Swastik, it's nice to meet you!  \\n\\nAs an AI myself, I'm always interested in connecting with other people working in the field. What kind of AI engineering do you specialize in?  \\n\\nI'm happy to chat about anything AI related, or just get to know you better.\\n\"),\n",
    "        HumanMessage(content=\"Hey, what's my name and what do i do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Swastik,\\n\\nIt's nice to meet you! That's fascinating, I'm always interested to learn about people working in the field of AI. \\n\\nWhat kind of AI engineering do you specialize in? Are you working on any particularly exciting projects at the moment?\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is swastik and I am a AI engineer\")\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Swastik.  üòÑ \\n\\nI remember it from our introduction! \\n\\n\\n\\nIs there anything else you'd like to talk about?  Perhaps you'd like to discuss your work as an AI engineer?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 99, 'total_tokens': 149, 'completion_time': 0.090909091, 'prompt_time': 0.004284321, 'queue_time': 0.238629057, 'total_time': 0.095193412}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-40088548-0b8c-47e0-87ec-a52860cbe161-0', usage_metadata={'input_tokens': 99, 'output_tokens': 50, 'total_tokens': 149})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you, Swastik! \\n\\nIs there anything I can help you with today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the config \n",
    "config1 = {\"configurable\":{\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is swastik\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Swastik.  \\n\\nI remember that from when you introduced yourself! üòÑ  \\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi, my name is swastik and I am a AI engineer', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Swastik,\\n\\nIt's nice to meet you! That's fascinating, I'm always interested to learn about people working in the field of AI. \\n\\nWhat kind of AI engineering do you specialize in? Are you working on any particularly exciting projects at the moment?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 23, 'total_tokens': 85, 'completion_time': 0.112727273, 'prompt_time': 0.002122986, 'queue_time': 0.233025112, 'total_time': 0.114850259}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f95ba3aa-b306-454b-b7f4-f5c07e43d8e6-0', usage_metadata={'input_tokens': 23, 'output_tokens': 62, 'total_tokens': 85}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Your name is Swastik.  üòÑ \\n\\nI remember it from our introduction! \\n\\n\\n\\nIs there anything else you'd like to talk about?  Perhaps you'd like to discuss your work as an AI engineer?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 99, 'total_tokens': 149, 'completion_time': 0.090909091, 'prompt_time': 0.004284321, 'queue_time': 0.238629057, 'total_time': 0.095193412}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-40088548-0b8c-47e0-87ec-a52860cbe161-0', usage_metadata={'input_tokens': 99, 'output_tokens': 50, 'total_tokens': 149})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='My name is swastik', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's nice to meet you, Swastik! \\n\\nIs there anything I can help you with today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 15, 'total_tokens': 45, 'completion_time': 0.054545455, 'prompt_time': 0.002030246, 'queue_time': 0.236186653, 'total_time': 0.056575701}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-2126662f-5d98-4b80-8b68-87be03c9804e-0', usage_metadata={'input_tokens': 15, 'output_tokens': 30, 'total_tokens': 45}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Swastik.  \\n\\nI remember that from when you introduced yourself! üòÑ  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 58, 'total_tokens': 81, 'completion_time': 0.041818182, 'prompt_time': 0.003873071, 'queue_time': 0.234133197, 'total_time': 0.045691253}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5180e03-dfe6-4a51-9df7-12a181a0a977-0', usage_metadata={'input_tokens': 58, 'output_tokens': 23, 'total_tokens': 81})])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∏‡•ç‡§µ‡§∏‡•ç‡§§‡§ø‡§ï!  ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§§‡•Å‡§Æ‡§∏‡•á ‡§Æ‡§ø‡§≤‡§®‡•á ‡§ï‡•Ä‡•§  \\n\\n‡§Ö‡§ó‡§∞ ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•ã‡§ó‡§æ ‡§§‡•ã ‡§™‡•Ç‡§õ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§ï‡•ã‡§ö ‡§® ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Å‡§ó‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§â‡§∏‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§π‡•Ç‡§Å‡•§ üòä \\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({'messages':[HumanMessage(content=\"hi my name is Swastik\")], \"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∏‡•ç‡§µ‡§∏‡•ç‡§§‡§ø‡§ï! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ú‡•ã ‡§≠‡•Ä ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Ç‡§ó‡§æ‡•§ \\n\\n‡§Ü‡§™‡§ï‡•á ‡§ï‡•ã‡§à ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§π‡•à‡§Ç? \\n\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, I am Swastik\")],\n",
    "     \"language\": \"Hindi\"},\n",
    "     config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage conversation history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have access to your personal information, including your ice cream preferences. \\n\\nWhat's your favorite flavor?  üç¶üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 86, 'total_tokens': 122, 'completion_time': 0.065454545, 'prompt_time': 0.005529289, 'queue_time': 0.232944972, 'total_time': 0.070983834}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d21ac1cc-61ab-4cd5-b501-78c0fb4f95bf-0', usage_metadata={'input_tokens': 86, 'output_tokens': 36, 'total_tokens': 122})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked what 2 + 2 equals.  üòä \\n\\n\\n\\nLet me know if you want to try another one! \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 88, 'total_tokens': 117, 'completion_time': 0.052727273, 'prompt_time': 0.004306811, 'queue_time': 0.23260087000000002, 'total_time': 0.057034084}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-faa2cc13-0178-4a85-bee3-a28908c4a87e-0', usage_metadata={'input_tokens': 88, 'output_tokens': 29, 'total_tokens': 117})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"What math problem did i ask for?\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrap this in message history\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {'configurable':{'session_id':'chat5'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I have no memory of past conversations. So, I don't know what math problem you asked me before.\\n\\nPlease tell me the math problem you'd like me to solve, and I'll do my best to help! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 35, 'total_tokens': 95, 'completion_time': 0.109090909, 'prompt_time': 0.002863654, 'queue_time': 0.234101481, 'total_time': 0.111954563}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-33c5a959-dff7-4008-afb4-521d7fef4da8-0', usage_metadata={'input_tokens': 35, 'output_tokens': 60, 'total_tokens': 95})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"What math problem did i ask for?\")],\n",
    "        \"language\":\"English\"\n",
    "    },\n",
    "    config=config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
